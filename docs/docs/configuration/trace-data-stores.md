# Trace Data Stores

Probably the most important part of Tracetest is how it retrieves traces from an operation that just happened. The process which does that is called `Trace Polling`, which connects to your trace data store and keeps watching for changes in a specific trace. Internally, Tracetest considers a trace as **complete** when it retrieve the trace twice in a row and the number of spans in that trace have not changed. Therefore, configuring how the trace poller works is crucial for you to get consistent results.

There are two parts of this configuration, how to connect to your trace data store and which strategy to use to fetch those traces.

## Trace store

Trace data store is the piece of software that you use to store your traces. There are several stores available in the market: Jaeger, Tempo, DataDog, OpenSearch, and the list goes on.

Each store requires a different configuration for Tracetest to be able to connect to it. Check the configuration for each store:

1. [Jaeger](data-stores/jaeger)
2. [OpenSearch](data-stores/opensearch)
3. [SignalFX](data-stores/signalfx)
4. [Tempo](data-stores/tempo)

> :information_source: In case the trace store you use is not supported by Tracetest, you can still use your OpenTelemetry Collector to send traces generated by tests directly to your Tracetest instance.

## Polling strategy

> :information_source: At the moment, Tracetest only allows a single strategy to be used. More strategies will be added later and if you have a suggestion of strategy to detecting if the trace is complete, please [open an issue](https://github.com/kubeshop/tracetest/issues) suggesting your idea.

There are two configurations you want to customize: `maxWaitTimeForTrace` and `retryDelay`. The first tells Tracetest how long it should try to wait for a complete trace. If Tracetest cannot get a complete trace before this period has passed, the test will fail with a message `timed out waiting for traces after x`.

A good rule of thumb is to use your longest operation duration plus some safety margin, say 50% for example. So, in case your longest operation takes 7 minutes, you can set this configuration as `7m + 3.5m = 10.5m`.

The `retryDelay` configuration tells Tracetest how often it should try to check if the trace has changed. Let's say you set it as `5s`. It means that every 5 seconds, tracetest will connect to your trace storage and get the latest trace available. Keep in mind that if the same trace is returned twice in a row, Tracetest will consider the trace as complete and start runnning your assertions on it.

This is a tricky configuration to get right because if you set a very small time there, you might get incomplete traces very often, but if you set a long time, your tests take more time to be complete executing.

A good configuration to start with would be twice the period which your application sends traces to your trace data store. It's important to consider your OpenTelemetry configuration as well, as it might batch your traces before sending them to the data store.

Imagine your application batches trace spans and send them to a collector every 5 seconds and then your collector also batches the spans and send them every 10 seconds. It's safe to assume that your traces will be sent to your data store 15 seconds after it was generated by your application. So this would be the minimal value you should consider as your `retryDelay`.

> :information_source: Some data stores take longer to make your trace available. While Jaeger is almost instant in that matter, SignalFX might take up to a minute. So, when configuring the retryDelay, also consider how long your data store might take to make the trace available.

#### Example
```yaml
poolingConfig:
    maxWaitTimeForTrace: 10m
    retryDelay: 5s
```
